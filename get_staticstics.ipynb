{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from clearml import Task\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "pd.options.display.max_columns=60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import clearml\n",
    "clearml.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mape(true, pred):\n",
    "    return 100 * ((true-pred)/true).abs().mean()\n",
    "\n",
    "def metric_main(true, pred):\n",
    "    return (1 - np.sum(np.abs(true-pred))/np.sum(true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# task_ids = Task.query_tasks(project_name='zra/0407')\n",
    "task_ids = Task.query_tasks(task_filter={'parent': \"b5f9c93309b04ebc98497080d4584b0b\"})\n",
    "\n",
    "# task_ids = Task.get_tasks(project_name='zra/0407')\n",
    "# task_id = task_ids.pop()\n",
    "# task = Task.get_task(task_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# task = Task.get_task(\"d3e5bcb46d2a4a25a5df5850fda375d7\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# {'dataset': {'dataset_file_name': 'dataset_ws60.parquet',\n",
    "#   'dataset_id': '5dc94de095014553acbe4f011a579241'},\n",
    "#  'dataset_params': {'analog_group': '150',\n",
    "#   'business_unit': 'all',\n",
    "#   'log_target': 'True',\n",
    "#   'scaler_kwargs': '',\n",
    "#   'scaling': 'Standard',\n",
    "#   'split_date': '01.01.2021',\n",
    "#   'target_column_name_formatter': 'predict_normalized_{}',\n",
    "#   'window_size': '120'},\n",
    "#  'kflod_kwargs_params': {'n_splits': '5', 'shuffle': 'False'},\n",
    "#  'model_kwargs_params': {'alpha': '1.0',\n",
    "#   'max_depth': '20',\n",
    "#   'n_estimators': '50'},\n",
    "#  'model_type_params': {'model_type': 'RandomForestRegressor',\n",
    "#   'save_kfold_predicts': 'True',\n",
    "#   'save_model': 'False',\n",
    "#   'use_kfold': 'False'}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dict(task_ids):\n",
    "    all_data = []\n",
    "    for task_id in task_ids:\n",
    "        task = Task.get_task(task_id)\n",
    "        if task.status!='completed':\n",
    "            continue\n",
    "        parameters = task.get_parameters_as_dict()\n",
    "        scalars = task.get_reported_scalars()\n",
    "                \n",
    "        mae = scalars['month']['mae']\n",
    "        mae = pd.Series(index=mae['x'], data=mae['y'], name=mae['name'])\n",
    "        rmse = scalars['month']['rmse']\n",
    "        rmse = pd.Series(index=rmse['x'], data=rmse['y'], name=rmse['name'])\n",
    "\n",
    "        all_data.append((parameters, (mae, rmse)))\n",
    "    return all_data\n",
    "\n",
    "\n",
    "def parse_all_data(all_data):\n",
    "    res = []\n",
    "\n",
    "    for x in all_data:\n",
    "        d = {}\n",
    "        d['metrics'] = x[1]\n",
    "        d['bu'] = params['dataset_params']['business_unit']\n",
    "        d['analog'] = params['dataset_params']['analog_group']\n",
    "        d['log_target'] = params['dataset_params']['log_target']\n",
    "        d['scaling'] = params['dataset_params']['scaling']\n",
    "        d['target_column_name_formatter'] = params['dataset_params']['target_column_name_formatter']\n",
    "        d['window_size'] = params['dataset_params']['window_size']\n",
    "        d['use_kfold'] = params['model_type_params']['use_kfold']\n",
    "        d['model_type'] = params['model_type_params']['model_type']\n",
    "        d['model_kwargs_params'] = params['model_kwargs_params']\n",
    "        d['max_depth'] = d['model_kwargs_params']['max_depth']\n",
    "        d['n_estimators'] = d['model_kwargs_params']['n_estimators']\n",
    "        res.append(d)\n",
    "    return res\n",
    "\n",
    "# def uniq_combinations(l: list, keys=['bu', 'analog']):\n",
    "#     return set(map(lambda x: tuple([x[key] for key in keys]), l))\n",
    "\n",
    "def make_res_df(res):\n",
    "    res_df = pd.DataFrame(list(map(lambda x: {key: value for key, value in x.items() if key!='metrics'}, res)))\n",
    "    res_df = res_df.merge(pd.concat(list(map(lambda x: x['metrics'][0], res)), axis=1).T.rename({i: f'mae_{i}' for i in range(12)}, axis=1).reset_index(drop=True), left_index=True, right_index=True)\n",
    "    res_df = res_df.merge(pd.concat(list(map(lambda x: x['metrics'][1], res)), axis=1).T.rename({i: f'rmse_{i}' for i in range(12)}, axis=1).reset_index(drop=True), left_index=True, right_index=True)\n",
    "    return res_df\n",
    "\n",
    "def plot_metrics(res_df, groupby='analog'):\n",
    "    mae_cols = [f'mae_{i}' for i in range(12)]\n",
    "    rmse_cols = [f'rmse_{i}' for i in range(12)]\n",
    "    for key, group in res_df.groupby(groupby):\n",
    "        group[mae_cols].T.plot(legend=False, title=key, ylabel='mae')\n",
    "        group[rmse_cols].T.plot(legend=False, title=key, ylabel='rmse')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_data_rf = []\n",
    "\n",
    "# # for task_id in map(lambda x: x.task_id, task_ids):\n",
    "# for task_id in task_ids:\n",
    "#     task = Task.get_task(task_id)\n",
    "#     # if task.status=='completed' and len(task.get_tags())>0:\n",
    "#     if task.status=='completed' and task.parent==\"b5f9c93309b04ebc98497080d4584b0b\":\n",
    "#         parameters = task.get_parameters_as_dict()\n",
    "#         scalars = task.get_reported_scalars()\n",
    "                \n",
    "#         mae = scalars['month']['mae']\n",
    "#         mae = pd.Series(index=mae['x'], data=mae['y'], name=mae['name'])\n",
    "#         rmse = scalars['month']['rmse']\n",
    "#         rmse = pd.Series(index=rmse['x'], data=rmse['y'], name=rmse['name'])\n",
    "\n",
    "#         all_data_rf.append((parameters, (mae, rmse)))\n",
    "\n",
    "all_data_rf = make_dict(task_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_rf.__len__(), task_ids.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_rf = parse_all_data(all_data_rf)\n",
    "res_df_rf = make_res_df(res_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_cols = [f'mae_{i}' for i in range(12)]\n",
    "rmse_cols = [f'rmse_{i}' for i in range(12)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for key, group in res_df.groupby('analog'):\n",
    "#     # print(group.shape)\n",
    "#     # break\n",
    "#     group[mae_cols].plot()\n",
    "#     group[rmse_cols].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for key, group in res_df.groupby('analog'):\n",
    "#     # print(group.shape)\n",
    "#     # break\n",
    "#     group[mae_cols].T.plot(legend=False, title=key, ylabel='mae')\n",
    "#     group[rmse_cols].T.plot(legend=False, title=key, ylabel='rmse')\n",
    "\n",
    "plot_metrics(res_df_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_ids_cb = Task.query_tasks(project_name='zra/0507', task_filter={'parent': \"9950fc7379eb4cd29d95701c713d3444\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_cb = make_dict(task_ids_cb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_cb.__len__(), task_ids_cb.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_cb = parse_all_data(all_data_cb)\n",
    "res_df_cb = make_res_df(res_cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df_cb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df = pd.concat([res_df_cb, res_df_rf]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics(res_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[idxmin]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = []\n",
    "\n",
    "for key, df in res_df.groupby('analog'):\n",
    "    for metric in ['mae', 'rmse']:\n",
    "        for month in range(12):\n",
    "            t = f\"{metric}_{month}\"\n",
    "            # print(key, t, df.loc[df[t].idxmin()][['model_type']].values[0])\n",
    "            idxmin = df[t].idxmin()\n",
    "            res.append((key, metric, month, idxmin, df.loc[idxmin]['model_type'], df.loc[idxmin]['window_size']))\n",
    "\n",
    "res = pd.DataFrame(res, columns=['bu', 'metric', 'month', 'idxmin', 'model_type', 'window_size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res['model_type'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.groupby(['bu', 'metric']).agg({'model_type': 'value_counts'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.groupby(['month']).agg({'model_type': 'value_counts'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.groupby(['window_size']).agg({'model_type': ['value_counts']}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "126/(126+32+34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df.groupby('analog')[['mae_0', 'mae_1', 'mae_2', 'mae_3',\n",
    "       'mae_4', 'mae_5', 'mae_6', 'mae_7', 'mae_8', 'mae_9', 'mae_10',\n",
    "       'mae_11']] \\\n",
    "        .min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df.groupby('analog')[['rmse_0', 'rmse_1', 'rmse_2', 'rmse_3', 'rmse_4', 'rmse_5',\n",
    "       'rmse_6', 'rmse_7', 'rmse_8', 'rmse_9', 'rmse_10', 'rmse_11']] \\\n",
    "        .min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Посмотрим на предикты, где не было логарифмирования\n",
    "\n",
    "- 7c330a572c3f4f9c90c24f133a531b35 - 500\n",
    "- de0210eef5bc4d498c867b9f834ae4f5 - 100\n",
    "- dc0c9989cc714296a75332804513bd30 - 200\n",
    "\n",
    "Оно было везде..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# task = Task.get_task(\"7c330a572c3f4f9c90c24f133a531b35\")\n",
    "task = Task.get_task(\"de0210eef5bc4d498c867b9f834ae4f5\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = task.artifacts['model_results'].get_local_copy()\n",
    "with open(path, 'rb') as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = task.get_parameters_as_dict()['dataset_params']['target_column_name_formatter']\n",
    "\n",
    "months = len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "month = 9\n",
    "true_pred = data[month]['X_test_with_predict'][[f\"predict_{month}\", target.format(month), 'model_predict']]\n",
    "true_pred\n",
    "# true_pred.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = Task.get_task(\"dc0c9989cc714296a75332804513bd30\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = task.artifacts['model_results'].get_local_copy()\n",
    "with open(path, 'rb') as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = task.get_parameters_as_dict()['dataset_params']['target_column_name_formatter']\n",
    "\n",
    "months = len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "month = 0\n",
    "true_pred = data[month]['X_test_with_predict'][[f\"predict_{month}\", target.format(month), 'model_predict']]\n",
    "true_pred\n",
    "# true_pred.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error(true_pred['predict_normalized_0'], true_pred['model_predict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Для Василия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = Task.get_task(\"9950fc7379eb4cd29d95701c713d3444\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = task.get_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_ids_cb = Task.query_tasks(task_filter={'parent': \"9950fc7379eb4cd29d95701c713d3444\"})\n",
    "analog_dict = dict()\n",
    "\n",
    "for task_id in task_ids_cb:\n",
    "    task = Task.get_task(task_id)\n",
    "    parameters = task.get_parameters()\n",
    "    analog = parameters['dataset_params/analog_group']\n",
    "    if analog in analog_dict.keys():\n",
    "        continue\n",
    "    \n",
    "    path = task.artifacts['model_results'].get_local_copy()\n",
    "    with open(path, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "\n",
    "    target = task.get_parameters_as_dict()['dataset_params']['target_column_name_formatter']\n",
    "\n",
    "    months = len(data)\n",
    "    preds = []\n",
    "    for month in range(months):\n",
    "        df = data[month]['X_test_with_predict'][['cut_date', 'model_predict']].rename({'model_predict': \"predict_{}\".format(month)}, axis=1)\n",
    "        preds.append(df)\n",
    "    preds = reduce(lambda a, b: a.merge(b, on='cut_date'), preds)\n",
    "    analog_dict[analog] = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# с true\n",
    "\n",
    "task_ids_cb = Task.query_tasks(task_filter={'parent': \"9950fc7379eb4cd29d95701c713d3444\"})\n",
    "analog_dict = dict()\n",
    "\n",
    "for task_id in task_ids_cb:\n",
    "    task = Task.get_task(task_id)\n",
    "    parameters = task.get_parameters()\n",
    "    analog = parameters['dataset_params/analog_group']\n",
    "    if analog in analog_dict.keys():\n",
    "        continue\n",
    "    \n",
    "    path = task.artifacts['model_results'].get_local_copy()\n",
    "    with open(path, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "\n",
    "    target = task.get_parameters_as_dict()['dataset_params']['target_column_name_formatter']\n",
    "\n",
    "    months = len(data)\n",
    "    preds = []\n",
    "    true = []\n",
    "    for month in range(months):\n",
    "        df = data[month]['X_test_with_predict'][['cut_date', 'model_predict']].rename({'model_predict': \"predict_{}\".format(month)}, axis=1)\n",
    "        df[\"predict_{}\".format(month)] = np.expm1(df[\"predict_{}\".format(month)])\n",
    "        preds.append(df)\n",
    "\n",
    "        df = data[month]['X_test_with_predict'][['cut_date', f'predict_{month}']].rename({f'predict_{month}': \"true_{}\".format(month)}, axis=1)\n",
    "        true.append(df)\n",
    "    preds = preds + true\n",
    "    preds = reduce(lambda a, b: a.merge(b, on='cut_date'), preds)\n",
    "    preds = preds.reset_index().rename(columns={'index': 'DN'})\n",
    "    preds['DN'] = analog\n",
    "    analog_dict[analog] = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analog_dict['500']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(r'D:\\gpn\\for_vasiliy.pkl', 'wb') as f:\n",
    "#     pickle.dump(analog_dict, f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in analog_dict:\n",
    "    analog_dict[key]['DN'] = key\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat(analog_dict.values()).reset_index(drop=True).to_excel(r'D:\\gpn\\for_vasiliy\\for_vasiliy3.xlsx', index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# look processing\n",
    "analysis.ipunb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from typing import List, Dict, Optional, Tuple, Union, Any\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "from utils.preprocessing import init_scaler_original, init_scaler, columns_for_deletion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test(\n",
    "    data_df: pd.DataFrame,\n",
    "    business_unit: str,\n",
    "    analog_group: str,\n",
    "    window_size: int,\n",
    "    split_date: datetime.date,\n",
    "    n_predict: int,\n",
    "    target_column_name_formatter: str,\n",
    "    log_target: bool = False,\n",
    "    scaling: Optional[str] = None,\n",
    "    scaler_kwargs: Optional[Dict[str, Any]] = None,\n",
    "    drop_not_scalable: bool = True\n",
    "):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        data_df (pd.DataFrame): Preprocessed dataframe\n",
    "        analog_group (Union[str, int]): Specific group of analogs.\n",
    "        window_size (int): number of days used to create the dataset.\n",
    "        split_date (datetime.date): day relative to which the train and test are divided.\n",
    "        n_predict (int): What month is the prediction for.\n",
    "        target_column_name_formatter (str): What value is predicted.\n",
    "        log_target (bool, optional): whether to logarithm target or not. Defaults to False.\n",
    "        scaling (Optional[str], optional): whether use specific scaling or not. Defaults to None.\n",
    "        scaler_kwargs (Optional[Dict[str, Any]], optional): Scaler kwargs if needed. Defaults to None.\n",
    "        drop_not_scalable (bool, optional): _description_. Defaults to True.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: _description_\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    if isinstance(split_date, str):\n",
    "        # split_date = datetime.datetime.strptime(split_date, \"%d.%m.%Y\").date()\n",
    "        split_date = pd.to_datetime(split_date)\n",
    "\n",
    "    valid_scaling = ['MinMaxScaler', 'StandardScaler']\n",
    "    valid_scaling += ['MinMax', 'Standard']\n",
    "\n",
    "    target_column_name = target_column_name_formatter.format(n_predict)\n",
    "    # if target_column_name not in data_df.columns:\n",
    "    #     raise ValueError(f'Missed columns: {target_column_name}')\n",
    "\n",
    "    # check scaling\n",
    "    if scaling and scaling not in valid_scaling:\n",
    "        raise ValueError(\"scaling_type must be one of %r.\" % valid_scaling)\n",
    "\n",
    "    # tdf = data_df[(data_df['business_unit'] == business_unit) &\n",
    "    #               (data_df['material_cd'] == analog_group) &\n",
    "    #               (data_df['window_size'] == window_size)\n",
    "    #               ]\n",
    "\n",
    "    print(f\"Unique window_sizes: {data_df['window_size'].unique()}\")\n",
    "\n",
    "    tdf = data_df[(data_df['business_unit'] == business_unit)]\n",
    "    print(tdf.shape[0])\n",
    "    tdf = tdf[tdf['material_cd'] == analog_group]\n",
    "    print(tdf.shape[0])\n",
    "    # tdf = tdf[tdf['window_size'] == window_size]\n",
    "    # print(tdf.shape[0])\n",
    "\n",
    "\n",
    "    # split to train and test\n",
    "    date_to_split = split_date - relativedelta(days=30) * (n_predict + 1)\n",
    "    date_split_query = tdf['cut_date'].dt.date < date_to_split\n",
    "\n",
    "    # train_slice = tdf[date_split_query]\n",
    "    # test_slice = tdf[~date_split_query]\n",
    "\n",
    "    train_slice = tdf[tdf['cut_date'].dt.date < date_to_split]\n",
    "    test_slice = tdf[tdf['cut_date'].dt.date >= split_date]\n",
    "\n",
    "    # work around target\n",
    "    y_train = train_slice[target_column_name]\n",
    "    y_test = test_slice[target_column_name]\n",
    "\n",
    "    if log_target:\n",
    "        y_train = np.log1p(y_train)\n",
    "        y_test = np.log1p(y_test)\n",
    "\n",
    "    if scaler_kwargs is None or len(scaler_kwargs)==0:\n",
    "        scaler_kwargs = {}\n",
    "    # scaling, scaler = self.init_scaler(scaling, **scaler_kwargs)\n",
    "    scaling, scaler = init_scaler_original(scaling, **scaler_kwargs)\n",
    "\n",
    "    # delete cut_date, mtr_cd, business_unit, w_size, predicts\n",
    "    columns_to_drop = ['cut_date', 'material_cd',\n",
    "                       'business_unit', 'window_size']\n",
    "    columns_to_drop += columns_for_deletion(tdf, startswith='predict')\n",
    "\n",
    "    # X_train = train_slice.drop(columns_to_drop, axis=1)\n",
    "    # X_test = test_slice.drop(columns_to_drop, axis=1)\n",
    "    X_train = train_slice[:]\n",
    "    X_test = test_slice[:]\n",
    "\n",
    "    # # delete stock_bmu_count in sum_df dataset\n",
    "    # if mtr_group == \"all\":\n",
    "    #     X_train = X_train.drop(['stock_bmu_count'], axis=1)\n",
    "    #     X_test = X_test.drop(['stock_bmu_count'], axis=1)\n",
    "    print(f\"Train Shape : {train_slice.shape}, Test Shape {test_slice.shape}\")\n",
    "\n",
    "    if X_train.shape[0]==0:\n",
    "        return X_train, X_test, y_train, y_test\n",
    "\n",
    "    # applying scaling\n",
    "    if scaling:\n",
    "        columns_list = X_train.columns\n",
    "        columns_list_ = list(set(X_train.columns) - set(columns_to_drop))\n",
    "\n",
    "        X_train_ = scaler.fit_transform(X_train[columns_list_])\n",
    "        X_test_ = scaler.transform(X_test[columns_list_])\n",
    "\n",
    "        X_train.loc[:, columns_list_] = X_train_\n",
    "        X_test.loc[:, columns_list_] = X_test_\n",
    "\n",
    "        # X_train = pd.DataFrame(\n",
    "        #     X_train, columns=columns_list, index=train_slice.index)\n",
    "        # X_test = pd.DataFrame(X_test, columns=columns_list,\n",
    "        #                     index=test_slice.index)\n",
    "\n",
    "        if not drop_not_scalable:\n",
    "            for col in columns_to_drop:\n",
    "                X_train[col] = train_slice[col]\n",
    "                X_test[col] = test_slice[col]\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "month = 0\n",
    "df = data[month]['X_test_with_predict']\n",
    "df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['predict_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_ids = Task.query_tasks(task_filter={'parent': \"b5f9c93309b04ebc98497080d4584b0b\"})\n",
    "task_id = task_ids.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# task = Task.get_task(task_id)\n",
    "task = Task.get_task(\"a9d8474580904ad8a70a7db35cb27bdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = task.artifacts['model_results'].get_local_copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path, 'rb') as f:\n",
    "    df = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df), len(df[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[0].keys(), df[1].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task.get_parameters_as_dict()['dataset_params']['target_column_name_formatter']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[1]['X_test_with_predict']#['predict_normalized_']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for task_id in task_ids:\n",
    "    task = Task.get_task(task_id)\n",
    "    path = task.artifacts['model_results'].get_local_copy()\n",
    "    with open(path, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "\n",
    "    target = task.get_parameters_as_dict()['dataset_params']['target_column_name_formatter']\n",
    "\n",
    "    months = len(data)\n",
    "    # true_preds = []\n",
    "    for month in range(months):\n",
    "        model_true = {target.format(month): \"model_true\"}\n",
    "        true_pred = data[month]['X_test_with_predict'].rename(model_true, axis=1)[['model_true', 'model_predict']]\n",
    "        # true_preds.append(true_pred)\n",
    "        true = true_pred['model_true']\n",
    "        pred = true_pred['model_predict']\n",
    "        mapes.append(mape(true, pred))\n",
    "    break\n",
    "        \n",
    "\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = []\n",
    "\n",
    "# for task_id in map(lambda x: x.task_id, task_ids):\n",
    "for task_id in task_ids:\n",
    "    if task.status!='completed':\n",
    "        continue\n",
    "    task = Task.get_task(task_id)\n",
    "    path = task.artifacts['model_results'].get_local_copy()\n",
    "    with open(path, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    \n",
    "    parameters = task.get_parameters_as_dict()\n",
    "    scalars = task.get_reported_scalars()\n",
    "            \n",
    "    mae = scalars['month']['mae']\n",
    "    mae = pd.Series(index=mae['x'], data=mae['y'], name=mae['name'])\n",
    "    rmse = scalars['month']['rmse']\n",
    "    rmse = pd.Series(index=rmse['x'], data=rmse['y'], name=rmse['name'])\n",
    "\n",
    "    target = parameters['dataset_params']['target_column_name_formatter']\n",
    "    months = len(data)\n",
    "\n",
    "    mapes = []\n",
    "    maes = []\n",
    "    rmses = []\n",
    "    \n",
    "    for month in range(months):\n",
    "        model_true = {target.format(month): \"model_true\"}\n",
    "        true_pred = data[month]['X_test_with_predict'].rename(model_true, axis=1)[['model_true', 'model_predict']]\n",
    "\n",
    "        true = true_pred['model_true']\n",
    "        pred = true_pred['model_predict']\n",
    "\n",
    "        true = np.expm1(true)\n",
    "        pred = np.expm1(pred)\n",
    "\n",
    "        mapes.append(mape(true, pred))\n",
    "        rmses.append(mean_squared_error(true, pred, squared=False))\n",
    "        maes.append(mean_absolute_error(true, pred))\n",
    "\n",
    "    mapes = pd.Series(data=mapes, name='mape')\n",
    "    rmses = pd.Series(data=rmses, name='rmse')\n",
    "    maes = pd.Series(data=maes, name='mae')\n",
    "\n",
    "    all_data.append((parameters, (maes, rmses, mapes)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_all_data(all_data):\n",
    "    res = []\n",
    "\n",
    "    for x in all_data:\n",
    "        d = {}\n",
    "        d['metrics'] = x[1]\n",
    "        d['bu'] = params['dataset_params']['business_unit']\n",
    "        d['analog'] = params['dataset_params']['analog_group']\n",
    "        d['log_target'] = params['dataset_params']['log_target']\n",
    "        d['scaling'] = params['dataset_params']['scaling']\n",
    "        d['target_column_name_formatter'] = params['dataset_params']['target_column_name_formatter']\n",
    "        d['window_size'] = params['dataset_params']['window_size']\n",
    "        d['use_kfold'] = params['model_type_params']['use_kfold']\n",
    "        d['model_type'] = params['model_type_params']['model_type']\n",
    "        d['model_kwargs_params'] = params['model_kwargs_params']\n",
    "        d['max_depth'] = d['model_kwargs_params']['max_depth']\n",
    "        d['n_estimators'] = d['model_kwargs_params']['n_estimators']\n",
    "        res.append(d)\n",
    "    return res\n",
    "\n",
    "# def uniq_combinations(l: list, keys=['bu', 'analog']):\n",
    "#     return set(map(lambda x: tuple([x[key] for key in keys]), l))\n",
    "\n",
    "def make_res_df(res):\n",
    "    res_df = pd.DataFrame(list(map(lambda x: {key: value for key, value in x.items() if key!='metrics'}, res)))\n",
    "    res_df = res_df.merge(pd.concat(list(map(lambda x: x['metrics'][0], res)), axis=1).T.rename({i: f'mae_{i}' for i in range(12)}, axis=1).reset_index(drop=True), left_index=True, right_index=True)\n",
    "    res_df = res_df.merge(pd.concat(list(map(lambda x: x['metrics'][1], res)), axis=1).T.rename({i: f'rmse_{i}' for i in range(12)}, axis=1).reset_index(drop=True), left_index=True, right_index=True)\n",
    "    return res_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = parse_all_data(all_data)\n",
    "res_df = make_res_df(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# all metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_ids_cb = Task.query_tasks(project_name='zra/0507', task_filter={'parent': \"9950fc7379eb4cd29d95701c713d3444\"}) # cb\n",
    "task_ids_rf = Task.query_tasks(task_filter={'parent': \"b5f9c93309b04ebc98497080d4584b0b\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_cb = []\n",
    "\n",
    "# for task_id in map(lambda x: x.task_id, task_ids):\n",
    "for task_id in task_ids_cb:\n",
    "    task = Task.get_task(task_id)\n",
    "    if task.status!='completed':\n",
    "        continue\n",
    "    path = task.artifacts['model_results'].get_local_copy()\n",
    "    with open(path, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "\n",
    "    if len(data)==0:\n",
    "        continue\n",
    "    \n",
    "    parameters = task.get_parameters_as_dict()\n",
    "    scalars = task.get_reported_scalars()\n",
    "\n",
    "    target = parameters['dataset_params']['target_column_name_formatter']\n",
    "    months = len(data)\n",
    "\n",
    "    d = []\n",
    "    for month in range(months):\n",
    "        model_true = {target.format(month): \"model_true\"}\n",
    "        true_pred = data[month]['X_test_with_predict'].rename(model_true, axis=1)[['cut_date', 'model_true', 'model_predict']]\n",
    "        true_pred = true_pred.query('cut_date<\\'2021-06-01\\'')\n",
    "        true_pred['model_predict'] = np.expm1(true_pred['model_predict'])\n",
    "\n",
    "        # true = true_pred['model_true']\n",
    "        # pred = true_pred['model_predict']\n",
    "\n",
    "        # mapes.append(mape(true, pred))\n",
    "        # rmses.append(mean_squared_error(true, pred, squared=False))\n",
    "        # maes.append(mean_absolute_error(true, pred))\n",
    "        d.append(true_pred)\n",
    "\n",
    "    # data = reduce(lambda a, b: a.merge(b, on='cut_date))\n",
    "\n",
    "    # mapes = pd.Series(data=mapes, name='mape')\n",
    "    # rmses = pd.Series(data=rmses, name='rmse')\n",
    "    # maes = pd.Series(data=maes, name='mae')\n",
    "\n",
    "    # all_data_cb.append((parameters, (maes, rmses, mapes)))\n",
    "    all_data_cb.append((parameters, d))\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_rf = []\n",
    "\n",
    "# for task_id in map(lambda x: x.task_id, task_ids):\n",
    "for task_id in task_ids_rf:\n",
    "    task = Task.get_task(task_id)\n",
    "    if task.status!='completed':\n",
    "        continue\n",
    "    path = task.artifacts['model_results'].get_local_copy()\n",
    "    with open(path, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "\n",
    "    if len(data)==0:\n",
    "        continue\n",
    "    \n",
    "    parameters = task.get_parameters_as_dict()\n",
    "    scalars = task.get_reported_scalars()\n",
    "\n",
    "    target = parameters['dataset_params']['target_column_name_formatter']\n",
    "    months = len(data)\n",
    "\n",
    "    d = []\n",
    "    for month in range(months):\n",
    "        model_true = {target.format(month): \"model_true\"}\n",
    "        true_pred = data[month]['X_test_with_predict'].rename(model_true, axis=1)[['cut_date', 'model_true', 'model_predict']]\n",
    "        true_pred = true_pred.query('cut_date<\\'2021-06-01\\'')\n",
    "        true_pred['model_predict'] = np.expm1(true_pred['model_predict'])\n",
    "\n",
    "        # true = true_pred['model_true']\n",
    "        # pred = true_pred['model_predict']\n",
    "\n",
    "        # mapes.append(mape(true, pred))\n",
    "        # rmses.append(mean_squared_error(true, pred, squared=False))\n",
    "        # maes.append(mean_absolute_error(true, pred))\n",
    "        d.append(true_pred)\n",
    "\n",
    "    # data = reduce(lambda a, b: a.merge(b, on='cut_date))\n",
    "\n",
    "    # mapes = pd.Series(data=mapes, name='mape')\n",
    "    # rmses = pd.Series(data=rmses, name='rmse')\n",
    "    # maes = pd.Series(data=maes, name='mae')\n",
    "\n",
    "    # all_data_cb.append((parameters, (maes, rmses, mapes)))\n",
    "    all_data_rf.append((parameters, d))\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_data = []\n",
    "for params, data in all_data_cb:\n",
    "    mae = []\n",
    "    rmse = []\n",
    "    mapes = []\n",
    "    d = {}\n",
    "    d['bu'] = params['dataset_params']['business_unit']\n",
    "    d['analog'] = params['dataset_params']['analog_group']\n",
    "    d['log_target'] = params['dataset_params']['log_target']\n",
    "    d['scaling'] = params['dataset_params']['scaling']\n",
    "    d['target_column_name_formatter'] = params['dataset_params']['target_column_name_formatter']\n",
    "    d['window_size'] = params['dataset_params']['window_size']\n",
    "    d['use_kfold'] = params['model_type_params']['use_kfold']\n",
    "    d['model_type'] = params['model_type_params']['model_type']\n",
    "    d['model_kwargs_params'] = params['model_kwargs_params']\n",
    "    d['max_depth'] = d['model_kwargs_params']['max_depth']\n",
    "    d['n_estimators'] = d['model_kwargs_params']['n_estimators']\n",
    "    for month_data in data:\n",
    "        mae.append(mean_absolute_error(month_data['model_true'], month_data['model_predict']))\n",
    "        rmse.append(mean_squared_error(month_data['model_true'], month_data['model_predict'], squared=False))\n",
    "        mapes.append(mape(month_data['model_true'], month_data['model_predict']))\n",
    "    d.update({f\"mae_{i}\": mae[i] for i in range(12)})\n",
    "    d.update({f\"rmse_{i}\": rmse[i] for i in range(12)})\n",
    "    d.update({f\"mape_{i}\": mapes[i] for i in range(12)})\n",
    "    cb_data.append(d)\n",
    "\n",
    "cb_data = pd.DataFrame(cb_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_data = []\n",
    "for params, data in all_data_rf:\n",
    "    mae = []\n",
    "    rmse = []\n",
    "    mapes = []\n",
    "    d = {}\n",
    "    d['bu'] = params['dataset_params']['business_unit']\n",
    "    d['analog'] = params['dataset_params']['analog_group']\n",
    "    d['log_target'] = params['dataset_params']['log_target']\n",
    "    d['scaling'] = params['dataset_params']['scaling']\n",
    "    d['target_column_name_formatter'] = params['dataset_params']['target_column_name_formatter']\n",
    "    d['window_size'] = params['dataset_params']['window_size']\n",
    "    d['use_kfold'] = params['model_type_params']['use_kfold']\n",
    "    d['model_type'] = params['model_type_params']['model_type']\n",
    "    d['model_kwargs_params'] = params['model_kwargs_params']\n",
    "    d['max_depth'] = d['model_kwargs_params']['max_depth']\n",
    "    d['n_estimators'] = d['model_kwargs_params']['n_estimators']\n",
    "    for month_data in data:\n",
    "        mae.append(mean_absolute_error(month_data['model_true'], month_data['model_predict']))\n",
    "        rmse.append(mean_squared_error(month_data['model_true'], month_data['model_predict'], squared=False))\n",
    "        mapes.append(mape(month_data['model_true'], month_data['model_predict']))\n",
    "    d.update({f\"mae_{i}\": mae[i] for i in range(12)})\n",
    "    d.update({f\"rmse_{i}\": rmse[i] for i in range(12)})\n",
    "    d.update({f\"mape_{i}\": mapes[i] for i in range(12)})\n",
    "    rf_data.append(d)\n",
    "\n",
    "rf_data = pd.DataFrame(rf_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics(res_df, groupby='analog'):\n",
    "    mae_cols = [f'mae_{i}' for i in range(12)]\n",
    "    rmse_cols = [f'rmse_{i}' for i in range(12)]\n",
    "    mape_cols = [f'mape_{i}' for i in range(12)]\n",
    "    for key, group in res_df.groupby(groupby):\n",
    "        group[mae_cols].T.plot(legend=False, title=key, ylabel='mae')\n",
    "        group[rmse_cols].T.plot(legend=False, title=key, ylabel='rmse')\n",
    "        group[mape_cols].T.plot(legend=False, title=key, ylabel='mape')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics(cb_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics(rf_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiple_metrics(y_true, y_pred):\n",
    "    \"\"\"1) Метрика помесячная (как была)\n",
    "        2) Метрика Квартальная (сумма по кварталу)\n",
    "        3) Метрика Полгодовая (сумма по полгоду)\n",
    "        4) Метрика Годовая (сумма по Годовая)\n",
    "        5) Метрика помесячная по 2м полугодам (сумма по полугодам)\"\"\"\n",
    "\n",
    "    # y_true = torch.Tensor(y_true)\n",
    "    # y_pred = torch.Tensor(y_pred)\n",
    "\n",
    "    metrics = []\n",
    "    metrics.append(metric_main(y_true, y_pred))\n",
    "\n",
    "    metric_q = metric_main(y_true.reshape(4, -1).sum(axis=1), y_pred.reshape(4, -1).sum(axis=1))\n",
    "    metric_h = metric_main(y_true.reshape(2, -1).sum(axis=1), y_pred.reshape(2, -1).sum(axis=1))\n",
    "    metric_y = metric_main(y_true.reshape(1, -1).sum(axis=1), y_pred.reshape(1, -1).sum(axis=1))\n",
    "    metric_1h = metric_main(y_true.reshape(2, -1)[0], y_pred.reshape(2, -1)[0])\n",
    "    metric_2h = metric_main(y_true.reshape(2, -1)[1], y_pred.reshape(2, -1)[1])\n",
    "    metrics.extend([metric_q, metric_h, metric_y, metric_1h, metric_2h])\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_data_2 = []\n",
    "for params, data in all_data_cb:\n",
    "    mae = []\n",
    "    rmse = []\n",
    "    mapes = []\n",
    "    super_metric = []\n",
    "    d = {}\n",
    "    d['bu'] = params['dataset_params']['business_unit']\n",
    "    d['analog'] = params['dataset_params']['analog_group']\n",
    "    d['log_target'] = params['dataset_params']['log_target']\n",
    "    d['scaling'] = params['dataset_params']['scaling']\n",
    "    d['target_column_name_formatter'] = params['dataset_params']['target_column_name_formatter']\n",
    "    d['window_size'] = params['dataset_params']['window_size']\n",
    "    d['use_kfold'] = params['model_type_params']['use_kfold']\n",
    "    d['model_type'] = params['model_type_params']['model_type']\n",
    "    d['model_kwargs_params'] = params['model_kwargs_params']\n",
    "    d['max_depth'] = d['model_kwargs_params']['max_depth']\n",
    "    d['n_estimators'] = d['model_kwargs_params']['n_estimators']\n",
    "\n",
    "    for month_data in data:\n",
    "        mae.append(mean_absolute_error(month_data['model_true'].iloc[:1], month_data['model_predict'].iloc[:1]))\n",
    "        rmse.append(mean_squared_error(month_data['model_true'].iloc[:1], month_data['model_predict'].iloc[:1], squared=False))\n",
    "        mapes.append(mape(month_data['model_true'].iloc[:1], month_data['model_predict'].iloc[:1]))\n",
    "        # super_metric.append(metric_main(month_data['model_true'].iloc[:1], month_data['model_predict'].iloc[:1]))\n",
    "        super_metric.append((month_data['model_true'].iloc[0], month_data['model_predict'].iloc[0]))\n",
    "    super_metric = np.array(super_metric)\n",
    "    super_metric2 = metric_main(super_metric[:, 0], super_metric[:, 1])\n",
    "    d.update({f\"mae_{i}\": mae[i] for i in range(12)})\n",
    "    d.update({f\"rmse_{i}\": rmse[i] for i in range(12)})\n",
    "    d.update({f\"mape_{i}\": mapes[i] for i in range(12)})\n",
    "    # d.update({f\"metric_main_{i}\": super_metric[i] for i in range(12)})\n",
    "    # d.update({f\"metric_main\": super_metric2})\n",
    "    d.update({f\"metric_main{key}\": value for key, value in zip(['', '_q', '_h', '_y', '_1h', '_2h'], multiple_metrics(super_metric[:, 0], super_metric[:, 1]))})\n",
    "    cb_data_2.append(d)\n",
    "\n",
    "cb_data_2 = pd.DataFrame(cb_data_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"metric_main\tmetric_main_q\tmetric_main_h\tmetric_main_y\tmetric_main_1h\tmetric_main_2h\".split('\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_data_2[['analog', 'metric_main',\n",
    " 'metric_main_q',\n",
    " 'metric_main_h',\n",
    " 'metric_main_y',\n",
    " 'metric_main_1h',\n",
    " 'metric_main_2h']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = []\n",
    "\n",
    "for key, df in cb_data_2.groupby('analog'):\n",
    "    for metric in ['metric_main', 'metric_main_q', 'metric_main_h', \n",
    "                    'metric_main_y', 'metric_main_1h', 'metric_main_2h']:\n",
    "        # print(key, metric, df[metric].agg([min, 'mean', max]).values)\n",
    "        l.append((key, metric, *df[metric].agg([min, 'mean', max]).values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(l, columns=['analog', 'metric', 'min', 'mean', 'max']).to_excel('metric_main.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, df in cb_data_2.groupby('analog'):\n",
    "    plt.figure(figsize=(15,5))\n",
    "    plt.title(key)\n",
    "    # plt.hist(df['metric_main'].values)\n",
    "    sns.violinplot(df[['metric_main', 'metric_main_q', 'metric_main_h', 'metric_main_y',\n",
    "                       'metric_main_1h', 'metric_main_2h']])\n",
    "    plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_metrics_2(res_df, groupby='analog'):\n",
    "#     mae_cols = [f'mae_{i}' for i in range(12)]\n",
    "#     rmse_cols = [f'rmse_{i}' for i in range(12)]\n",
    "#     mape_cols = [f'mape_{i}' for i in range(12)]\n",
    "#     metric_main_cols = [f'metric_main_{i}' for i in range(12)]\n",
    "#     for key, group in res_df.groupby(groupby):\n",
    "#         group[mae_cols].T.plot(legend=False, title=key, ylabel='mae')\n",
    "#         group[rmse_cols].T.plot(legend=False, title=key, ylabel='rmse')\n",
    "#         group[mape_cols].T.plot(legend=False, title=key, ylabel='mape')\n",
    "#         group[metric_main_cols].T.plot(legend=False, title=key, ylabel='metric_main')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task.get_parameters()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
